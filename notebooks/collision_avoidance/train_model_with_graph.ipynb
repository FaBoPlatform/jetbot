{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collision Avoidance - Train Model(alexnetモデルの学習)\n",
    "\n",
    "このノートブックでは、衝突回避のために``free「直進する」``と``blocked「旋回する」``の2つのクラスを特定する画像分類モデルを学習します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## それでは、始めましょう\n",
    "まずは必要なライブラリを読み込みます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataset instance(データセットインスタンスを生成)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[torchvision.datasets](https://pytorch.org/docs/stable/torchvision/datasets.html)パッケージに含まれる``ImageFolder`` classを使用します。学習用のデータを準備するために、``torchvision.transforms``パッケージを使って画像変換を定義します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.ImageFolder(\n",
    "    'dataset',\n",
    "    transforms.Compose([\n",
    "        transforms.ColorJitter(0.1, 0.1, 0.1, 0.1),\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split dataset into train and test sets(トレーニングデータとテストデータに分ける)\n",
    "次に、データセットを*トレーニング用*と*テスト用*のデータセットに分割します。この例では、*トレーニング用*に50%, *テスト用*に50%で分けます。*テスト用*のデータセットは、学習中にモデルの精度を検証するために使用されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_percent = 0.5 # テストデータ件数を50%にする\n",
    "num_test = int(test_percent * len(dataset))\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [len(dataset) - num_test, num_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create data loaders to load data in batches(バッチ処理で学習データとテストデータを読み込むためのデータローダーを作成)\n",
    "\n",
    "[torch.utils.data.DataLoader](https://github.com/pytorch/pytorch/blob/master/torch/utils/data/dataloader.py)クラスは、モデル学習中に次のデータ処理が完了出来るようにサブプロセスで並列処理にして実装します。  \n",
    "データのシャッフル、バッチでのデータロードのために使用します。この例では、1回のバッチ処理で8枚の画像を使用します。これをバッチサイズと呼び、GPUのメモリ使用量と、モデルの精度に影響を与えます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=8,\n",
    "    shuffle=True,\n",
    "    num_workers=1\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=8,\n",
    "    shuffle=True,\n",
    "    num_workers=1\n",
    ")\n",
    "\n",
    "len(train_loader)\n",
    "len(test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Neural Network Model (JetBot用にモデルを変更する)\n",
    "\n",
    "torchvisionで使用可能なImageNetデータセットで学習済みのAlexNetモデルを使用します。\n",
    "\n",
    "*転移学習*と呼ばれる手法で、すでに画像分類できる特徴を持つニューラルネットワーク層を、別の目的のために作られたモデルに適用することで、短時間で良好な結果を得られるモデルを作成することができます。\n",
    "\n",
    "AlexNetの詳細: https://github.com/pytorch/vision/blob/master/torchvision/models/alexnet.py\n",
    "\n",
    "転移学習の詳細：https://www.youtube.com/watch?v=yofjFQddwHE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.alexnet(pretrained=True)\n",
    "# モデルを凍結して使う場合は、全てのパラメータが持つ学習フラグを無効化します。デフォルトはrequires_grad = Trueで全てのパラメータを再学習します。\n",
    "#for param in model.parameters():\n",
    "#    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`AlexNet`のモデルは出力層の手前にある層が4096のノード数を持ち、JetBotは出力を`free`,`blocked`の2種類にするため、モデルの出力層を(4096,2)で置き換えます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.classifier[6].in_features)\n",
    "model.classifier[6] = torch.nn.Linear(model.classifier[6].in_features, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "デフォルトではモデルのweightはCPUで処理されるため、GPUを利用するようにモデルを設定します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"before: {}\".format(model.classifier[6].weight.type()))\n",
    "device = torch.device('cuda')\n",
    "model = model.to(device)\n",
    "print(\"after: {}\".format(model.classifier[6].weight.type()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 視覚化ユーティリティ\n",
    "[bokeh](https://docs.bokeh.org/en/latest/docs/installation.html)を使って学習中の損失(loss)と精度(accuracy)をグラフに表示することができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.io import push_notebook, show, output_notebook\n",
    "from bokeh.layouts import row\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.models import ColumnDataSource\n",
    "from bokeh.models.tickers import SingleIntervalTicker\n",
    "output_notebook()\n",
    "\n",
    "colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728']\n",
    "\n",
    "p1 = figure(title=\"Loss\", x_axis_label=\"Epoch\", plot_height=300, plot_width=360)\n",
    "p2 = figure(title=\"Accuracy\", x_axis_label=\"Epoch\", plot_height=300, plot_width=360)\n",
    "\n",
    "source1 = ColumnDataSource(data={'epochs': [], 'trainlosses': [], 'testlosses': [] })\n",
    "source2 = ColumnDataSource(data={'epochs': [], 'train_accuracies': [], 'test_accuracies': []})\n",
    "\n",
    "#r = p1.multi_line(ys=['trainlosses', 'testlosses'], xs='epochs', color=colors, alpha=0.8, legend_label=['Training','Test'], source=source)\n",
    "r1 = p1.line(x='epochs', y='trainlosses', line_width=2, color=colors[0], alpha=0.8, legend_label=\"Train\", source=source1)\n",
    "r2 = p1.line(x='epochs', y='testlosses', line_width=2, color=colors[1], alpha=0.8, legend_label=\"Test\", source=source1)\n",
    "\n",
    "r3 = p2.line(x='epochs', y='train_accuracies', line_width=2, color=colors[0], alpha=0.8, legend_label=\"Train\", source=source2)\n",
    "r4 = p2.line(x='epochs', y='test_accuracies', line_width=2, color=colors[1], alpha=0.8, legend_label=\"Test\", source=source2)\n",
    "\n",
    "p1.legend.location = \"top_right\"\n",
    "p1.legend.click_policy=\"hide\"\n",
    "\n",
    "p2.legend.location = \"bottom_right\"\n",
    "p2.legend.click_policy=\"hide\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training(モデルの学習)\n",
    "\n",
    "30エポック学習し、各エポックで以前の最高精度と現在の精度を比較することにより、最高精度を更新した場合に保存します。  \n",
    "現在の精度が以前の最高精度と等しい場合は、損失の少ない方を保存します。\n",
    "\n",
    "> 1エポックは、私たちが用意したトレーニング用のデータ全部を1回学習することです。一度に8枚の画像を学習するミニバッチ処理を複数回実行することで1エポックが完了します。\n",
    "\n",
    "Jupyterは`メニュー>View>Show Log Console`でログを確認することができます。  \n",
    "何か問題がある場合は、ログを確認することができます。  \n",
    "また、グラフが表示されない場合は、このノートブックの代わりに`train_model.ipynb`を使って学習することもできます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 30\n",
    "BEST_MODEL_PATH = 'best_model.pth'\n",
    "best_accuracy = 0.0\n",
    "saved_loss = 1e9\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "handle = show(row(p1, p2), notebook_handle=True)\n",
    "\n",
    "print(\"学習を開始します。\")\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    \n",
    "    train_loss = 0.0 # for graph\n",
    "    train_error_count = 0.0 # for graph\n",
    "    for images, labels in iter(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = F.cross_entropy(outputs, labels)\n",
    "        train_loss += loss # for graph\n",
    "        train_error_count += float(torch.sum(torch.abs(labels - outputs.argmax(1)))) # for graph\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    train_loss /= len(train_loader)\n",
    "    \n",
    "    test_loss = 0.0 # for graph\n",
    "    test_error_count = 0.0\n",
    "    for images, labels in iter(test_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        loss = F.cross_entropy(outputs, labels)\n",
    "        test_loss += loss # for graph\n",
    "        test_error_count += float(torch.sum(torch.abs(labels - outputs.argmax(1))))\n",
    "    test_loss /= len(test_loader)\n",
    "    \n",
    "    train_accuracy = 1.0 - float(train_error_count) / float(len(train_dataset))\n",
    "    test_accuracy = 1.0 - float(test_error_count) / float(len(test_dataset))\n",
    "\n",
    "    # 今回のepoch学習のテスト結果がよければ保存します\n",
    "    is_saved = False\n",
    "    if test_accuracy > best_accuracy:\n",
    "        torch.save(model.state_dict(), BEST_MODEL_PATH)\n",
    "        best_accuracy = test_accuracy\n",
    "        saved_loss = test_loss\n",
    "        is_saved = True\n",
    "    elif test_accuracy == best_accuracy:\n",
    "        if test_loss < saved_loss:\n",
    "            torch.save(model.state_dict(), BEST_MODEL_PATH)\n",
    "            saved_loss = test_loss\n",
    "            is_saved = True\n",
    "\n",
    "    print('%d: %f, %f, %f, %f, ' % (epoch+1, train_loss, test_loss, train_accuracy, test_accuracy)+(\"saved\" if is_saved else \"not saved\"))\n",
    "\n",
    "\n",
    "    # 学習状況をグラフに表示します\n",
    "    new_data1 = {'epochs': [epoch+1],\n",
    "                 'trainlosses': [float(train_loss)],\n",
    "                 'testlosses': [float(test_loss)] }\n",
    "    source1.stream(new_data1)\n",
    "    new_data2 = {'epochs': [epoch+1],\n",
    "                 'train_accuracies': [float(train_accuracy)],\n",
    "                 'test_accuracies': [float(test_accuracy)] }\n",
    "    source2.stream(new_data2)\n",
    "    push_notebook(handle=handle)\n",
    "print(\"学習が終了しました。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習が完了すると、``live_demo.ipynb``で推論に使う``best_model.pth``が生成されます。\n",
    "\n",
    "※ グラフを初期化したい場合は、視覚化ユーティリティの項目のグラフの初期化をおこなっているCellを再度実行します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next(次)\n",
    "\n",
    "次は、`live_demo.ipynb`を実行します。  \n",
    "ノートブックメニューから`Kernel`->`Restert Kernel`を選んでJupyter kernelを再起動するか、JetBotを一度再起動してから次に進むとスムーズに進行できます。\n",
    "\n",
    "[live_demo.ipynb](./live_demo.ipynb) をクリックし、走行しましょう。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
