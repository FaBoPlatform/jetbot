{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collision Avoidance - Train Model (衝突回避 - alexnetモデルの学習)\n",
    "\n",
    "このノートブックでは、衝突回避のために``free「直進する」``と``blocked「旋回する」``の2つのクラスを特定する画像分類モデルを学習します。  \n",
    "モデルの学習には人気のあるディープラーニングライブラリの *PyTorch* を使います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "# 利用するライブラリを読み込みます。\n",
    "########################################\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データセットインスタンスを生成\n",
    "\n",
    "[torchvision.datasets](https://pytorch.org/docs/stable/torchvision/datasets.html)パッケージに含まれる``ImageFolder`` classを使用します。学習用のデータを準備するために、``torchvision.transforms``パッケージを使って画像変換を定義します。  \n",
    "pytorch ImageNetの学習に使われた140万件のデータセットから得られる各チャンネルの平均と標準偏差は以下の値になります。  \n",
    "RGB各要素の平均：[0.485, 0.456, 0.406]  \n",
    "RGB各要素の標準偏差：[0.229, 0.224, 0.225]  \n",
    "正規化に関する部分はライブデモの「カメラ画像の前処理作成」の部分でもう少し詳しく説明してあります。\n",
    "\n",
    "* ImageFolderリファレンス：\n",
    "  * https://pytorch.org/docs/stable/torchvision/datasets.html#imagefolder\n",
    "* ImageFolder実装コード：\n",
    "  * https://github.com/pytorch/vision/blob/master/torchvision/datasets/folder.py\n",
    "* Normalizeリファレンス：\n",
    "  * https://pytorch.org/docs/stable/torchvision/transforms.html\n",
    "* Normalize実装コード：\n",
    "  * https://github.com/pytorch/vision/blob/master/torchvision/transforms/transforms.py\n",
    "* 正規化パラメータの値の理由：\n",
    "  * https://stackoverflow.com/questions/58151507/why-pytorch-officially-use-mean-0-485-0-456-0-406-and-std-0-229-0-224-0-2\n",
    "* 正規化に意味があるのかどうか：\n",
    "  * https://teratail.com/questions/234027"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "# jpeg画像データを学習可能なデータフォーマットに変換して提供するインスタンスを作成します。\n",
    "# このデータセットは、アクセス毎にtransformsを実行するため、ColorJitterにより毎回色合いがランダムに変化します。\n",
    "# dataset変数には以下のような値が入ります。\n",
    "# dataset[データ番号][0]：(3x224x224)のCHWデータ（ColorJitterによりアクセス毎に色合いがランダムに変化します）\n",
    "# dataset[データ番号][1]：ラベル番号（blockedの場合は0、freeの場合は1）\n",
    "########################################\n",
    "dataset = datasets.ImageFolder(\n",
    "    'dataset',  # データセットのディレクトリパスを指定します。\n",
    "    transforms.Compose([\n",
    "        transforms.ColorJitter(0.1, 0.1, 0.1, 0.1),  # カラージッターは画像の明るさ、コントラスト、彩度をランダムに変更します。\n",
    "        transforms.Resize((224, 224)),  # 画像サイズを224x224にリサイズします。\n",
    "        transforms.ToTensor(),  # cudnnはHWC(Height x Width x Channel)をサポートしません。そのため画像(HWC layout)からTensor(CHW layout)に変換します。また、RGB各値を[0, 255]から[0.0, 1.0]の範囲にスケーリングします。\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # この値はpytorch ImageNetの学習に使われた正規化（ImageNetデータセットのRGB毎に平均を0、標準偏差が1になるようにスケーリングすること）のパラメータです。学習済みモデルをベースとした転移学習を行うため、カメラ画像はこの値でRGBを正規化することが望ましいでしょう。\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### トレーニングデータとテストデータに分ける\n",
    "次に、データセットを*トレーニング用*と*テスト用*のデータセットに分割します。この例では、*トレーニング用*に(データ総数-50)件、*テスト用*に50件で分けます。  \n",
    "*テスト用*のデータセットは、学習中にモデルの精度を検証するために使用されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "# 学習に使うデータと学習させずに精度検証のために使うデータに分けます。\n",
    "# blocked、freeの順で読込まれていたデータをランダムに抽出して、学習用と検証用にデータを分けます。\n",
    "########################################\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [len(dataset) - 50, 50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### バッチ処理で学習データとテストデータを読み込むためのデータローダーを作成\n",
    "\n",
    "[torch.utils.data.DataLoader](https://github.com/pytorch/pytorch/blob/master/torch/utils/data/dataloader.py)クラスは、モデル学習中に次のデータ処理が完了出来るようにサブプロセスで並列処理にして実装します。  \n",
    "データのシャッフル、バッチでのデータロードのために使用します。この例では、1回のバッチ処理で8枚の画像を使用します。これをバッチサイズと呼び、GPUのメモリ使用量と、モデルの精度に影響を与えます。\n",
    "\n",
    "* DataLoaderリファレンス：\n",
    "  * https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader\n",
    "* DataLoader実装コード：\n",
    "  * https://github.com/pytorch/pytorch/blob/master/torch/utils/data/dataloader.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "# データセットを分割読込みするためのデータローダーを作成します。\n",
    "########################################\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=8,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=8,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JetBot用にモデルを変更する\n",
    "\n",
    "torchvisionで使用可能なImageNetデータセットで学習済みのAlexNetモデルを使用します。\n",
    "\n",
    "*転移学習*と呼ばれる手法で、すでに画像分類できる特徴を持つニューラルネットワーク層を、別の目的のために作られたモデルに適用することで、短時間で良好な結果を得られるモデルを作成することができます。\n",
    "\n",
    "AlexNetの詳細：https://github.com/pytorch/vision/blob/master/torchvision/models/alexnet.py\n",
    "\n",
    "転移学習の詳細：https://www.youtube.com/watch?v=yofjFQddwHE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "# PyTorchで提供されているImageNetデータセットで学習済みのAlexNetモデルを読込みます。\n",
    "########################################\n",
    "model = models.alexnet(pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AlexNetの学習済みモデルは1000クラスのラベルを学習しています。しかしJetBotの衝突回避モデルの出力は「free」と「blocked」の2種類しか用意していません。  \n",
    "`AlexNet`のモデルは出力層の手前にある層が4096のノード数を持っているので、モデルの出力層を(4096,2)に置き換えて使います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "# モデルの出力層をJetBotの衝突回避モデル用に置き換えます。\n",
    "########################################\n",
    "model.classifier[6] = torch.nn.Linear(model.classifier[6].in_features, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "デフォルトではモデルのweightの計算はCPUで処理されるため、GPUを利用するようにモデルを設定します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "# GPU処理が可能な部分をGPUで処理するように設定します。\n",
    "########################################\n",
    "device = torch.device('cuda')\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モデルの学習\n",
    "30エポック学習し、各エポックでテストデータにおけるこれまでの最高精度と現在の精度を比較することにより、最高精度を更新した場合に保存します。  \n",
    "\n",
    "> 1エポックは、私たちが用意したトレーニング用のデータ全部を1回学習することです。一度に8枚の画像を学習するミニバッチ処理を複数回実行することで1エポックが完了します。\n",
    "\n",
    "* バックプロパゲーションと勾配更新の関係について：\n",
    "  * https://stackoverflow.com/questions/53975717/pytorch-connection-between-loss-backward-and-optimizer-step\n",
    "* torch.tensorとnp.ndarrayの違いについて：\n",
    "  * https://stackoverflow.com/questions/63582590/why-do-we-call-detach-before-calling-numpy-on-a-pytorch-tensor/63869655#63869655"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 30  # 学習するエポック数。\n",
    "BEST_MODEL_PATH = 'best_model.pth'  # 学習結果を保存するファイル名。\n",
    "best_accuracy = 0.0  # 検証用の初期精度は0%の精度を意味する0.0としておきます。\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)  # 確率的勾配降下法を実装します。学習率と運動量はJetBotの学習に適した値を指定します。\n",
    "\n",
    "########################################\n",
    "# 学習を開始します。\n",
    "########################################\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "\n",
    "    ####################\n",
    "    # SGDに基づいた学習をバッチ毎に実行します。\n",
    "    ####################\n",
    "    for images, labels in iter(train_loader):  # 8件分の学習データを読み込みます。\n",
    "        images = images.to(device)  # 画像データをGPUメモリに転送します。\n",
    "        labels = labels.to(device)  # ラベルデータをGPUメモリに転送します。\n",
    "        optimizer.zero_grad()  # 最適化されたすべてのtorch.Tensorの勾配をゼロに設定します。\n",
    "        outputs = model(images)  # 8件分の予測を一度に実行します。\n",
    "        loss = F.cross_entropy(outputs, labels)  # 8件分のモデルの予測結果と正解ラベルを照合して損失を計算します。\n",
    "        loss.backward()  # 各パラメータ毎の損失の勾配を計算します。\n",
    "        optimizer.step()  # 各パラメータの勾配を更新します。\n",
    "\n",
    "    ####################\n",
    "    # 未学習のデータでモデルの精度を検証します。\n",
    "    ####################\n",
    "    test_error_count = 0.0  # 不一致件数を0件として初期化します。\n",
    "    for images, labels in iter(test_loader): # 8件分のテストデータを読み込みます。\n",
    "        images = images.to(device)  # 画像データをGPUメモリに転送します。\n",
    "        labels = labels.to(device)  # ラベルデータをGPUメモリに転送します。\n",
    "        outputs = model(images)  # 8件分の予測を一度に実行します。\n",
    "        test_error_count += float(torch.sum(torch.abs(labels - outputs.argmax(1))))  # 予測結果と正解ラベルが不一致となった件数をカウントします。\n",
    "\n",
    "    test_accuracy = 1.0 - float(test_error_count) / float(len(test_dataset))  # 不一致となった割合から精度を算出します。\n",
    "    print('%d: %f' % (epoch, test_accuracy))  # 今回の評価結果をログに出力します。\n",
    "    if test_accuracy > best_accuracy:  # 過去最高の精度を更新した場合は保存します。\n",
    "        torch.save(model.state_dict(), BEST_MODEL_PATH)  # 学習したモデルをファイルに保存します。\n",
    "        best_accuracy = test_accuracy  # 過去最高の精度として値を保持します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習が完了すると、``live_demo_JP.ipynb``で推論に使う``best_model.pth``が生成されます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 次\n",
    "JetBot本体で学習した場合は、このノートブックを閉じてからJupyter左側にある「Running Terminals and Kernels」を選択して「train_model_JP.ipynb」の横にある「SHUT DOWN」をクリックしてJupyter Kernelをシャットダウンしてから[live_demo_JP.ipynb](live_demo_JP.ipynb)に進んでください。  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
