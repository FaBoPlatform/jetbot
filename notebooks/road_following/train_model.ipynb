{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Road Follower - Train Model(モデルの学習)\n",
    "\n",
    "このnotebookは、入力画像を読み込み、ターゲットに対応するx、y値のセットを出力するようにニューラルネットワークを学習します。\n",
    "\n",
    "road followerアプリのためにResNet18 neural networkアーキテクチャーモデルを学習するために、PyTorch deep learningフレームワークを使用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import glob\n",
    "import PIL.Image\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Dataset Instance(データセットインスタンスの作成)\n",
    "\n",
    "``__len__`` と ``__getitem__``関数が実装されたカスタマイズされた``torch.utils.data.Dataset`` の実装を生成します。このクラスは、画像をロードするための役割と、画像ファイル名からx、y値の値をパースして取得します。`torch.utils.data.Dataset``を実装する事で、すべてのtorchデータユーティリティを使用する事ができます。\n",
    "\n",
    "いくつかの変換（カラージッターなど）をデータセットにハードコーディングしました。ランダムな水平反転をオプションにしました（「右にとどまる」必要がある道路のように、非対称の経路をたどる場合）。ロボットが何らかの規則に従っているかどうかが重要でない場合は、フリップを有効にしてデータセットを拡張できます"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_x(path):\n",
    "    \"\"\"Gets the x value from the image filename\"\"\"\n",
    "    return (float(int(path[3:6])) - 50.0) / 50.0\n",
    "\n",
    "def get_y(path):\n",
    "    \"\"\"Gets the y value from the image filename\"\"\"\n",
    "    return (float(int(path[7:10])) - 50.0) / 50.0\n",
    "\n",
    "class XYDataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, directory, random_hflips=False):\n",
    "        self.directory = directory\n",
    "        self.random_hflips = random_hflips\n",
    "        self.image_paths = glob.glob(os.path.join(self.directory, '*.jpg'))\n",
    "        self.color_jitter = transforms.ColorJitter(0.3, 0.3, 0.3, 0.3)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        \n",
    "        image = PIL.Image.open(image_path)\n",
    "        x = float(get_x(os.path.basename(image_path)))\n",
    "        y = float(get_y(os.path.basename(image_path)))\n",
    "        \n",
    "        if float(np.random.rand(1)) > 0.5:\n",
    "            image = transforms.functional.hflip(image)\n",
    "            x = -x\n",
    "        \n",
    "        image = self.color_jitter(image)\n",
    "        image = transforms.functional.resize(image, (224, 224))\n",
    "        image = transforms.functional.to_tensor(image)\n",
    "        image = image.numpy()[::-1].copy()\n",
    "        image = torch.from_numpy(image)\n",
    "        image = transforms.functional.normalize(image, [0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        \n",
    "        return image, torch.tensor([x, y]).float()\n",
    "    \n",
    "dataset = XYDataset('dataset_xy', random_hflips=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split dataset into train and test sets(トレーニングとテスト用のデータセットに分ける)\n",
    "データセットをロードしたら、トレーニング用とテスト用のデータセットに分割します。この例では、トレーニング用が90%, テスト用が10%で分けます。テストセットは、トレーニングするモデルの精度を検証するために使用されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_percent = 0.1\n",
    "num_test = int(test_percent * len(dataset))\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [len(dataset) - num_test, num_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create data loaders to load data in batches(バッチでデータを読み込むためのdata loadersを作成)\n",
    "\n",
    "`` DataLoader``クラスは、並行したサブプロセスを使用して、データのシャッフル、バッチでのデータロードのために使用します。この例では、64のバッチサイズを使用します。バッチサイズは、GPUで使用可能なメモリに基づいており、モデルの精度に影響を与える可能性があります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=16,\n",
    "    shuffle=True,\n",
    "    num_workers=4\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=16,\n",
    "    shuffle=True,\n",
    "    num_workers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Neural Network Model (Neural netwrk modelの定義)\n",
    "\n",
    "PyToch TouchVisionで使用可能なResNet-18モデルを使用します。\n",
    "\n",
    "*転移学習*と呼ばれる手法で、利用可能なデータがはるかに少ない状態で新しいタスクをおこなうために、事前にトレーニングされたモデル（数百万の画像でトレーニングされた）を再利用する事ができます。\n",
    "\n",
    "ResNet-18の詳細: https://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py\n",
    "\n",
    "転移学習の詳細: https://www.youtube.com/watch?v=yofjFQddwHE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ResNetのモデルは、`in_features``として、512を最終レイヤーに全結合します。そして、``out_features``2(x,y座標)にして回帰のトレーニングをおこないます。\n",
    "\n",
    "最後に、GPUで実行するために、モデルを転送します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fc = torch.nn.Linear(512, 2)\n",
    "device = torch.device('cuda')\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Regression:\n",
    "\n",
    "70エポック学習し、損失が減少した場合は、ベストなモデルを保存します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 70\n",
    "BEST_MODEL_PATH = 'best_steering_model_xy.pth'\n",
    "best_loss = 1e9\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "epoch_list = []\n",
    "train_loss_list = []\n",
    "test_loss_list = []\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    \n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for images, labels in iter(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = F.mse_loss(outputs, labels)\n",
    "        train_loss += float(loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    train_loss /= len(train_loader)\n",
    "    \n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    for images, labels in iter(test_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        loss = F.mse_loss(outputs, labels)\n",
    "        test_loss += float(loss)\n",
    "    test_loss /= len(test_loader)\n",
    "    \n",
    "    print('%d : train loss %f, test_loss %f' % (epoch, train_loss, test_loss))\n",
    "    epoch_list.append(epoch) \n",
    "    train_loss_list.append(train_loss)\n",
    "    test_loss_list.append(test_loss)\n",
    "    if test_loss < best_loss:\n",
    "        torch.save(model.state_dict(), BEST_MODEL_PATH)\n",
    "        best_loss = test_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習が完了すると、Live demo notebookで推論に使う``best_steering_model_xy.pth``が生成されます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next(次)\n",
    "\n",
    "次は、live_demo.ipynbで学習済みモデルで自動走行します。\n",
    "\n",
    "TensorRTを試したい人は、trtフォルダの中のconvert_trt.ipynbを実行し、学習済みモデルをTensorRT形式に変換し、live_demo.ipynbを実行し自動走行します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
