{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Road Following（道路に沿った走行 - データの収集)\n",
    "このノートブックでは、カメラ画像を読み込み、JetBotが目指すべき道路上のポイントをクリックしてデータを収集します。  \n",
    "通常、ディープラーニングの学習データは画像ファイルとラベルファイルに分かれています。  \n",
    "カメラ画像はJpegファイルとして保存します。ラベルはクリックした画像の座標x, y値になりますが、ここではラベルファイルとして保存するのではなく、Jpegファイル名にx, yの値を付けて保存することにします。\n",
    "\n",
    "collision avoidanceを実行していれば、今回実行する次の3ステップには馴染みがあるでしょう。\n",
    "\n",
    "1. データ収集\n",
    "2. 学習\n",
    "3. 走行\n",
    "\n",
    "collision avoidanceでは、画像に対して2つのラベル「free」、「blocked」のどちらに該当するかを判断することができました。画像を2クラスに分類しているため、これを画像分類と呼びます。  \n",
    "road followingでも、データ収集から走行までは同じような流れで実行していきます。  \n",
    "ただし、今回はJetBotが道路（または任意のパスや通路、コース）を走行できるようにするために、画像分類の代わりに、**regression（回帰）**という別の手法で学習させます。\n",
    "\n",
    "このノートブックでの作業は簡単です。\n",
    "\n",
    " 1. JetBotを道路上のさまざまな位置に配置します（道路中央から離れた位置や、さまざまな方向など）。\n",
    "> ポイントは、JetBotが正常に走行するルートの他に、ルートから外れそうな所で正常なルートに戻すためのデータを取ることです。  \n",
    "> データの多様性こそが重要であると、collision avoidanceのときに覚えたはずです。\n",
    "\n",
    "2. JetBotのカメラ画像を画面に表示します。\n",
    "3. マウスで画像をクリックすることで、`緑の点`が追加された画像が表示されます。\n",
    "4. クリックすると画像と一緒にこの`緑の点`のX、Y座標が保存されます。\n",
    "\n",
    "ここでの重要な点は何でしょうか？ 下記が役立つと思われるガイドです。\n",
    "\n",
    "1. カメラのライブ映像を見ます。\n",
    "2. JetBotがたどるべき経路を想像します。\n",
    "3. JetBotが道路をふらつかずにまっすぐ進むことができるように、目標点はこの道路に沿ったできるだけ遠くの位置に配置します。\n",
    "> 例として、もし真っ直ぐの道路があったとします。目標点は地平線にします。もし道路が鋭く曲がったカーブなら、脱輪しないレベルでJetBotの近くに配置する必要があるでしょう。\n",
    "\n",
    "4. JetBotが道路から外れてしまいそうなときに、道路に戻すようなデータも取ります。\n",
    " \n",
    "ディープラーニングのモデルを意図したとおりに機能させるために、十分なデータ量を取得します。  \n",
    "意図したとおりに動作するモデルでは、以下の動作が期待できます。\n",
    "\n",
    "1. JetBotは、目標点に向かって安定して移動できます（道路の外に出ることなく）。\n",
    "2. 道路に沿って設定した目標点を目指して継続的に処理されます。\n",
    "\n",
    "`02_train_model_JP.ipynb`による学習では、集めたデータを基にX, Yの値の推論をおこなうモデルの学習をします。  \n",
    "`04_live_demo_trt_JP.ipynb`による自動走行では、予測されたX, Yの値からJetBotのステアリングの値を計算します。(角度は「完全に正確」ではありません。本来であればカメラレンズの歪みを補正するための画像キャリブレーションが必要になりますが、JetBotの動作は角度にほぼ比例するため、キャリブレーション無しでもJetBotの制御は正常に機能します)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ラベル付けのデモ動画\n",
    "\n",
    "下記URLの動画を参考に、画像にラベルを付ける方法の例を確認します。このモデルはたった123枚の画像で動作しました:)\n",
    "\n",
    "YouTubeのサンプル動画：[https://www.youtube.com/embed/FW4En6LejhI](https://www.youtube.com/embed/FW4En6LejhI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "HTML('<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/FW4En6LejhI\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ライブラリの読み込み\n",
    "それでは、「データ収集」の目的で必要なすべてのライブラリをインポートすることから始めましょう。 OpenCVを使用して画像をみながらラベル付けをします。画像ファイルの命名にはクリックした座標のX, Y値の他に、ファイル名が重複しないようにuuidライブラリも使用されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "# 利用するライブラリを読み込みます。\n",
    "########################################\n",
    "import ipywidgets  # Jupyter標準のウィジェットを利用します。\n",
    "import traitlets  # カメラ画像などのデータが更新されたときに、連動して処理を実行させるためにtraitletsライブラリを利用します。\n",
    "import ipywidgets.widgets as widgets  # Jupyter標準のウィジェットを利用します。\n",
    "from IPython.display import display  # ウィジェットを表示するためのdisplayライブラリを利用します。\n",
    "\n",
    "# JetBot用に用意したカメラ、画像変換、モーター制御ライブラリを利用します。\n",
    "from jetbot import Robot, Camera, bgr8_to_jpeg\n",
    "\n",
    "########################################\n",
    "# 画像注釈のために必要なPythonの基本的なライブラリを読み込みます。\n",
    "########################################\n",
    "from uuid import uuid1\n",
    "import os  # ディレクトリ作成のためにpython標準のosライブラリを利用します。\n",
    "import json  # jsonは使っていないので省略可能です。\n",
    "import glob  # 画像ファイル一覧取得のためのライブラリを利用します。\n",
    "import datetime  # 日付を取得するためのライブラリを利用します。（これはデータセットをzipファイルに圧縮する際に使われていますが、この日本語翻訳ノートブックでは不要のため削除してあります。）\n",
    "import numpy as np  # 数値計算ライブラリのnumpyを利用します。\n",
    "import cv2  # OpenCVライブラリを利用します。\n",
    "import time  # timeは使っていないので省略可能です。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データ収集\n",
    "\n",
    "クリック可能なカメラ画像を表示するウィジェットと、クリックした目標地点を画像にオーバーレイして表示するウィジェットを作成します。  \n",
    "今回はクリックしたX, Y座標を取得できるようにNVIDIAのjaybdubさんが作った[jupyter_clickable_image_widget](https://github.com/jaybdub/jupyter_clickable_image_widget)を利用します。これによりカメラ画面をクリックするだけでデータ収集が可能になります。\n",
    "\n",
    "JetBotのCameraクラスを使用して、CSI MIPIカメラを有効にします。私たちのニューラルネットワークは、224x224ピクセルの画像を入力として受け取ります。データセットのファイルサイズを最小化するために、カメラをそのサイズに設定します。JetBotはこの画像サイズで機能することを確認しています。  \n",
    "実施するシナリオによっては、もっと大きな画像サイズでデータを収集し、後で目的のサイズに縮小する方がよい場合があります。\n",
    "\n",
    "次のコードブロックには、左側にクリックできるカメラ映像ウィジェットが表示され、右側にはクリック後に目標地点が緑の丸で表示された画像のスナップショットのウィジェットが表示されます。\n",
    "その下には、保存した画像の数が表示されます。\n",
    "\n",
    "左側のライブ画像をクリックすると、「dataset_xy」ディレクトリにカメラ画像をjpegデータとして保存します。  \n",
    "その時のファイル名にはターゲットの座標x,yとuuidをが含まれています。  \n",
    "\n",
    "``xy_<x value>_<y value>_<uuid>.jpg``  \n",
    "\n",
    "学習時に、ファイル名からx,yの値を復元し、jpeg画像とともに読み込みます。\n",
    "\n",
    "実行時に`jupyter lab build`するようにポップアップが表示されることがあります。  \n",
    "これはターミナルで`sudo jupyter lab build`を実行すると解決します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "# 利用するライブラリを読み込みます。\n",
    "########################################\n",
    "from jupyter_clickable_image_widget import ClickableImageWidget  # 画像をクリックした点のx,y座標を取得するJupyter用ウィジェットを利用します。\n",
    "\n",
    "DATASET_DIR = 'dataset_xy'  # データ保存ディレクトリ名を定義します。\n",
    "\n",
    "########################################\n",
    "# データセット保存用のディレクトリを作成します。\n",
    "# ディレクトリがすでに存在する場合、ディレクトリ作成関数がエラーを返す可能性があるため、\n",
    "# ここは「try/except」ステートメントで囲みます。\n",
    "########################################\n",
    "try:\n",
    "    os.makedirs(DATASET_DIR)\n",
    "except FileExistsError:\n",
    "    print('ディレクトリが存在しているため、作成をスキップします。')\n",
    "\n",
    "########################################\n",
    "# カメラを有効化します。\n",
    "########################################\n",
    "camera = Camera(fps=4)\n",
    "\n",
    "########################################\n",
    "# カメラ画像表示用のウィジェットを用意します。\n",
    "########################################\n",
    "camera_widget = ClickableImageWidget(width=camera.width, height=camera.height)\n",
    "\n",
    "########################################\n",
    "# スナップショット画像表示用のウィジェットを用意します。\n",
    "########################################\n",
    "snapshot_widget = ipywidgets.Image(width=camera.width, height=camera.height)\n",
    "\n",
    "########################################\n",
    "# traitletsライブラリを利用してカメラ画像データが更新されたときに、\n",
    "# bgr8フォーマットをjpegフォーマットに変換してから\n",
    "# 画像表示ウィジェットに反映するように設定します。\n",
    "########################################\n",
    "traitlets.dlink((camera, 'value'), (camera_widget, 'value'), transform=bgr8_to_jpeg)\n",
    "\n",
    "########################################\n",
    "# 保存済みの画像ファイル数を表示するテキストボックスを作成します。\n",
    "########################################\n",
    "count_widget = ipywidgets.IntText(description='count')\n",
    "\n",
    "########################################\n",
    "# 保存済みの画像ファイル数を数えてウィジェットの値を初期化します。\n",
    "########################################\n",
    "count_widget.value = len(glob.glob(os.path.join(DATASET_DIR, '*.jpg')))\n",
    "\n",
    "########################################\n",
    "# カメラ画像ウィジェットが持つjpeg画像データを\n",
    "# 指定されたディレクトリにjpgファイルとして保存します。\n",
    "########################################\n",
    "def save_snapshot(_, content, msg):\n",
    "    ####################\n",
    "    # jupyter_clickable_image_widgetによってクリックイベントが検出された時に実行します。\n",
    "    ####################\n",
    "    if content['event'] == 'click':\n",
    "        data = content['eventData']  # jupyter_clickable_image_widgetによって提供されたイベント発生時のデータを取得します。\n",
    "        x = data['offsetX']  # jupyter_clickable_image_widgetによって提供されたクリックした画像のx座標を取得します。\n",
    "        y = data['offsetY']  # jupyter_clickable_image_widgetによって提供されたクリックした画像のy座標を取得します。\n",
    "\n",
    "        ####################\n",
    "        # ピクセル座標をパーセンテージに変換します。\n",
    "        # これは学習時のget_x()とget_y()関数に合わせた修正になります。\n",
    "        ####################\n",
    "        x_ratio = int((x/224)*100)\n",
    "        y_ratio = int((y/224)*100)\n",
    "        \n",
    "        ####################\n",
    "        # 保存するファイル名を決定します。\n",
    "        ####################\n",
    "        uuid = 'xy_%03d_%03d_%s' % (x_ratio, y_ratio, uuid1())\n",
    "        image_path = os.path.join(DATASET_DIR, uuid + '.jpg')\n",
    "\n",
    "        ####################\n",
    "        # カメラ画像ウィジェットが持つ画像データをファイルに保存します。\n",
    "        ####################\n",
    "        with open(image_path, 'wb') as f:\n",
    "            f.write(camera_widget.value)\n",
    "        \n",
    "        ####################\n",
    "        # スナップショットウィジェットにカメラ画像とクリックした場所を緑の丸で表示します。\n",
    "        ####################\n",
    "        snapshot = camera.value.copy()  # OpenCVカメラクラスが持つ画像データを、変数snapshotにコピーします。（ここでスナップショットに表示する画像はクリック時のカメラ画像ウィジェットのデータではないことに注意。ウィジェットが持つのはjpegデータなのでOpenCVで緑の丸を描くためにはbgrに変換する必要が発生します。）\n",
    "        snapshot = cv2.circle(snapshot, (int(x), int(y)), 8, (0, 255, 0), 3)  # クリックした座標に緑の丸を半径8ピクセル、太さ3ピクセルで描きます。\n",
    "        snapshot_widget.value = bgr8_to_jpeg(snapshot)  # OpenCV BGR画像をJpeg画像に変換してスナップショットウィジェットを更新します。\n",
    "        count_widget.value = len(glob.glob(os.path.join(DATASET_DIR, '*.jpg')))  # 保存済み画像ファイルを数え直して、カウントウィジェットを更新します。\n",
    "        \n",
    "########################################\n",
    "# jupyter_clickable_image_widgetで作られた\n",
    "# カメラウィジェットが（クリック）イベントを\n",
    "# 検出したときにsave_snapshot()関数が呼ばれるように\n",
    "# 紐づけます。\n",
    "########################################\n",
    "camera_widget.on_msg(save_snapshot)\n",
    "\n",
    "########################################\n",
    "# カメラ画像ウィジェットとスナップショットウィジェット\n",
    "# および保存件数表示ウィジェットをひとまとめにした\n",
    "# data_collection_widgetを作成します。\n",
    "########################################\n",
    "data_collection_widget = ipywidgets.VBox([\n",
    "    ipywidgets.HBox([camera_widget, snapshot_widget]),\n",
    "    count_widget\n",
    "])\n",
    "\n",
    "########################################\n",
    "# data_collection_widgetを表示します。\n",
    "########################################\n",
    "display(data_collection_widget)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# カメラの終了\n",
    "データを取り終えたら、他のノートブックでカメラを使用できるようにカメラの接続を適切に閉じましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera.stop()  # カメラを停止します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 次\n",
    "十分なデータを収集したら、トレーニングに進みます。  \n",
    "JetBot本体で学習する場合は、このノートブックを閉じてからJupyter左側にある「Running Terminals and Kernels」を選択して「01_data_collection_JP.ipynb」の横にある「SHUT DOWN」をクリックしてJupyter Kernelをシャットダウンしてから[02_train_model_JP.ipynb](02_train_model_JP.ipynb)に進んでください。  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
