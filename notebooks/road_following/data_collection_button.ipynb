{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Road Following \n",
    "このnotebookdでは、カメラ画像を読み込み、JetBotの進行方向となるターゲットポイントをクリックして、画像の座標となるx、y値を取得します。画像とx、y値を学習用のデータセットとして保存します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## パッケージの更新\n",
    "新しくなったJetBotの機能を使うために、一度ターミナルからパッケージの更新が必要となります。まだ更新していない場合は、下記の手順で更新を実行してください。  \n",
    "ターミナルは、JupyterのTerminalを起動するか、sshでJetBotにログインするか、キーボード+マウス+モニターをJetBotに接続してCtrl+ALT+Tでターミナルを開くことができます。\n",
    "\n",
    "* MAX-N mode:ビルド時間を短くするために、Jetsonの最高性能を出すためのモードに変更します。\n",
    "> sudo nvpmodel -m 0\n",
    "\n",
    "* nodejs:マウスクリックウィジェットで必要になります。\n",
    "> sudo python3 -m pip install git+https://github.com/ipython/traitlets@dead2b8cdde  \n",
    "sudo apt-get install -y curl  \n",
    "curl -sL https://deb.nodesource.com/setup_10.x | sudo -E bash -  \n",
    "sudo apt-get install -y nodejs libffi-dev  \n",
    "\n",
    "* jupyter_clickable_image_widget:マウスクリックウィジェット\n",
    "> cd\n",
    "git clone https://github.com/jaybdub/jupyter_clickable_image_widget  \n",
    "cd jupyter_clickable_image_widget  \n",
    "sudo -H pip3 install -e .  \n",
    "sudo jupyter labextension install js  \n",
    "\n",
    "* bokeh:グラフ表示ウィジェット\n",
    "> sudo apt-get install -y python3-matplotlib  \n",
    "sudo -H pip3 install bokeh  \n",
    "sudo jupyter labextension install @bokeh/jupyter_bokeh  \n",
    "\n",
    "* 5W mode:5V3AのモバイルバッテリーではMAX-Nモードの安定動作は電流的に厳しいので、5Wモードに変更します。\n",
    "> sudo nvpmodel -m 1\n",
    "\n",
    "* reboot:再起動します。モバイルバッテリーでMAX-Nモードのまま再起動すると起動しないことがあります。その場合は5VのACアダプターを使って起動後、5Wモードに変更してください。\n",
    "> sudo reboot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## それでは、始めましょう\n",
    "collision avoidanceを実行していれば、今回実行する次の3ステップには馴染みがあるでしょう。\n",
    "\n",
    "1. データ収集\n",
    "2. 学習\n",
    "3. 走行\n",
    "\n",
    "collision avoidanceでは、画像に対して2つのラベル（フリー、ブロック）のどちらに該当するかを判断することができました。画像を2クラスに分類しているため、これを画像分類と呼びます。  \n",
    "road followingでも、データ収集から走行までは同じような流れで実行していきます。  \n",
    "ただし、今回はJetBotが道路（または任意のパスや通路、コース）を走行できるようにするために、画像分類の代わりに、**回帰**という別の手法で学習させます。\n",
    "\n",
    " 1. JetBotを道路上のさまざまな位置に配置します（中心からのオフセット、さまざまな角度など）\n",
    "\n",
    "> データの多様性こそが重要であると、collision avoidanceのときに覚えたはずです。\n",
    "\n",
    "\n",
    "2. JetBotからのライブカメラの画像を画面に表示します\n",
    "3. マウスでX,Y座標を移動することで、`greenの点`をロボットが移動したい方向に移動します。\n",
    "4. この`greenの点`のX、Y座標の値をロボットのカメラからの画像と、一緒に保存します\n",
    "\n",
    "\n",
    "`train_model.ipynb`による学習では、集めたデータを基にX, Yの値の推論をおこなうための学習をします。`live_demo.ipynb`によるライブデモでは、JetBotのステアリングの値を計算するために予測されたX、Y値を使用します。(角度は「完全に正確」ではありません。本来であればカメラレンズの歪みを補正するための画像キャリブレーションが必要になりますが、JetBotの動作は角度にほぼ比例するため、キャリブレーション無しでもJetBotの制御は正常に機能します)\n",
    "\n",
    "それでは、この`data_collection.ipynb`の重要な点は何でしょうか？ 下記が役立つと思われるガイドです。\n",
    "\n",
    "1. カメラからのライブ映像を見ます\n",
    "2. JetBotがたどるべき経路を想像してください（道路からの脱輪などを回避するために必要な距離を計算してみてください）\n",
    "3. JetBotが道路をふらつかずにまっすぐ進むことができるように、目標点はこの経路に沿ったできるだけ遠くの位置に配置します。\n",
    "\n",
    "> 例として、もし真っ直ぐの道路があったとします、目標点は地平線にします。もし道路が鋭く曲がったカーブなら、脱輪しないレベルでJetBotの近くに配置する必要があるでしょう。\n",
    " \n",
    "ディープラーニングのモデルを意図したとおりに機能させるために、十分なデータ量を取得します。  \n",
    "意図したとおりに動作するモデルでは、以下の動作が期待できます。\n",
    "\n",
    "1. JetBotは、目標点に向かって安定して移動できます（道路の外に出ることなく）。\n",
    "2. 経路に沿って設定した目標点を目指して継続的に処理されます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labeling example video(ラベリングのデモ動画)\n",
    "\n",
    "下記URLの動画を参考に、画像にラベルを付ける方法の例を確認します。このモデルはたった123枚の画像で動作しました:)\n",
    "\n",
    "YouTubeのサンプル動画：[https://www.youtube.com/embed/FW4En6LejhI](https://www.youtube.com/embed/FW4En6LejhI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries(ライブラリの読み込み)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IPython Libraries for display and widgets\n",
    "import ipywidgets\n",
    "import traitlets\n",
    "import ipywidgets.widgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# Camera and Motor Interface for JetBot\n",
    "from jetbot import Robot, Camera, bgr8_to_jpeg\n",
    "\n",
    "# Python basic pakcages for image annotation\n",
    "from uuid import uuid1\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Live Camera Widget(ライブカメラウィジェットの作成)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本サンプルを実行するにあたり、まずnvargus-daemon(カメラ等で使用)をリスタートします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo jetbot | sudo -S systemctl restart nvargus-daemon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "カメラの初期化と表示をおこないます。\n",
    "\n",
    "JetBotのカメラクラスは、CSI MIPI cameraを有効にするために使います。road followingに使うニューラルネットワークのモデルでは、224x224ピクセルの画像データを入力として使います。画像サイズが大きくなると、ニューラルネットワークモデルの学習や実行に必要とするメモリ量と処理時間が大幅に増えます。Jetson Nanoでは最適な値としてこのサイズを設定します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera = Camera.instance(width=224, height=224, fps=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Collection(データ収集)\n",
    "\n",
    "カメラ画像とカメラ画像にターゲットを追加したウィジェットを作成します。今回は画像をクリックしてデータ注釈の座標を取得できるようにする[jupyter_clickable_image_widget](https://github.com/jaybdub/jupyter_clickable_image_widget)と呼ばれる特別なipywidgetを使用します。これによりカメラ画面をクリックするだけでデータ収集が可能になります。\n",
    "\n",
    "カメラ画像を保存する機能を作成します。\n",
    "\n",
    "1. 目標点をクリックします。\n",
    "\n",
    "カメラ画面をクリックすると、カメラ画像をターゲットの座標x,yとuuidをファイル名に含めて保存します。  \n",
    "これは``dataset_xy``フォルダーに、  \n",
    "``xy_<x value>_<y value>_<uuid>.jpg``  \n",
    "の形式で保存されます。\n",
    "\n",
    "学習時に、ファイル名からx,yの値を復元し、イメージとともに読み込みます。\n",
    "\n",
    "実行時に`jupyter lab build`するようにポップアップが表示されることがあります。  \n",
    "これはターミナルで`sudo jupyter lab build`を実行すると解決します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jupyter_clickable_image_widget import ClickableImageWidget\n",
    "DATASET_DIR = 'dataset_xy'\n",
    "\n",
    "# we have this \"try/except\" statement because these next functions can throw an error if the directories exist already\n",
    "try:\n",
    "    os.makedirs(DATASET_DIR)\n",
    "except FileExistsError:\n",
    "    print('Directories not created becasue they already exist')\n",
    "\n",
    "# create image preview\n",
    "camera_widget = ClickableImageWidget(width=camera.width, height=camera.height)\n",
    "snapshot_widget = ipywidgets.Image(width=camera.width, height=camera.height)\n",
    "camera_link = traitlets.dlink((camera, 'value'), (camera_widget, 'value'), transform=bgr8_to_jpeg)\n",
    "\n",
    "# create widgets\n",
    "count_widget = ipywidgets.IntText(description='count')\n",
    "# manually update counts at initialization\n",
    "count_widget.value = len(glob.glob(os.path.join(DATASET_DIR, '*.jpg')))\n",
    "\n",
    "# カメラ画像を保存する機能を作成します。\n",
    "def save_snapshot(_, content, msg):\n",
    "    if content['event'] == 'click':\n",
    "        data = content['eventData']\n",
    "        x = data['offsetX']\n",
    "        y = data['offsetY']\n",
    "        \n",
    "        # save to disk\n",
    "        #dataset.save_entry(category_widget.value, camera.value, x, y)\n",
    "        x_ratio = int((x/224)*100)\n",
    "        y_ratio = int((y/224)*100)\n",
    "        uuid = 'xy_%03d_%03d_%s' % (x_ratio, y_ratio, uuid1())\n",
    "        image_path = os.path.join(DATASET_DIR, uuid + '.jpg')\n",
    "        with open(image_path, 'wb') as f:\n",
    "            f.write(camera_widget.value)\n",
    "        \n",
    "        # display saved snapshot\n",
    "        snapshot = camera.value.copy()\n",
    "        snapshot = cv2.circle(snapshot, (x, y), 8, (0, 255, 0), 3)\n",
    "        snapshot_widget.value = bgr8_to_jpeg(snapshot)\n",
    "        count_widget.value = len(glob.glob(os.path.join(DATASET_DIR, '*.jpg')))\n",
    "        \n",
    "camera_widget.on_msg(save_snapshot)\n",
    "\n",
    "data_collection_widget = ipywidgets.VBox([\n",
    "    ipywidgets.HBox([camera_widget, snapshot_widget]),\n",
    "    count_widget\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 操作ボタンを作成\n",
    "\n",
    "画像データを集めやすくするために、basic motionと同じようにボタン操作でJetBotを操作出来るように準備します。  \n",
    "ボタンは後ほどカメラ画面と一緒に表示します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robot = Robot()\n",
    "\n",
    "def stop(change):\n",
    "    robot.stop()\n",
    "\n",
    "# カーペットの上だと旋回出来ないことがあるので、少し出力を上げます。\n",
    "def step_forward(change):\n",
    "    robot.forward(0.6)\n",
    "    time.sleep(0.3)\n",
    "    robot.stop()\n",
    "\n",
    "def step_backward(change):\n",
    "    robot.backward(0.6)\n",
    "    time.sleep(0.3)\n",
    "    robot.stop()\n",
    "\n",
    "def step_left(change):\n",
    "    robot.left(0.6)\n",
    "    time.sleep(0.1)\n",
    "    robot.stop()\n",
    "\n",
    "def step_right(change):\n",
    "    robot.right(0.6)\n",
    "    time.sleep(0.1)\n",
    "    robot.stop()\n",
    "\n",
    "# create control buttons\n",
    "button_layout = widgets.Layout(width='100px', height='80px', align_self='center')\n",
    "stop_button = widgets.Button(description='stop', button_style='danger', layout=button_layout)\n",
    "forward_button = widgets.Button(description='forward', layout=button_layout)\n",
    "backward_button = widgets.Button(description='backward', layout=button_layout)\n",
    "left_button = widgets.Button(description='left', layout=button_layout)\n",
    "right_button = widgets.Button(description='right', layout=button_layout)\n",
    "\n",
    "# link buttons to actions\n",
    "stop_button.on_click(stop)\n",
    "forward_button.on_click(step_forward)\n",
    "backward_button.on_click(step_backward)\n",
    "left_button.on_click(step_left)\n",
    "right_button.on_click(step_right)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 画面と操作ボタンを表示して始めよう\n",
    "\n",
    "次のコードを実行すると、画面と操作ボタンが表示されます。  \n",
    "左の画面でJetBotが目標とする場所をクリックすると、データが追加されます。クリックした箇所は右の画面に緑色のまるで表示されます。  \n",
    "JetBotを操作しながら、100枚程度のデータがあればうまく学習できると思います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# control buttons\n",
    "middle_box = widgets.HBox([left_button, stop_button, right_button], layout=widgets.Layout(align_self='center'))\n",
    "controls_box = widgets.VBox([forward_button, middle_box, backward_button])\n",
    "\n",
    "display(widgets.HBox([\n",
    "    data_collection_widget,\n",
    "    # display buttons\n",
    "    widgets.VBox([\n",
    "        controls_box\n",
    "    ])\n",
    "]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# カメラ停止\n",
    "最後に、他のノートブックでカメラを使うために、このノートブックで使ったカメラを停止しておきます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_link.unlink()  # ブラウザへのストリーミングを停止します（カメラは引き続き実行されています）\n",
    "camera.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next(次)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次は、``train_model.ipynb``で学習をおこないます。  \n",
    "ノートブックメニューから`Kernel`->`Restert Kernel`を選んでJupyter kernelを再起動するか、JetBotを一度再起動してから次に進むとスムーズに進行できます。\n",
    "\n",
    "[train_model.ipynb](./train_model.ipynb) をクリックし、移動します。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
