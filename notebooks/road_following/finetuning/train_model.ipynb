{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Road Following - モデルの学習(resnet18モデルの学習)\n",
    "このnotebookでは、入力画像を読み込み、ターゲットに対応するx、y値のセットを出力するようにニューラルネットワークを学習します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## パッケージの更新\n",
    "新しくなったJetBotの機能を使うために、一度ターミナルからパッケージの更新が必要となります。まだ更新していない場合は、下記の手順で更新を実行してください。  \n",
    "ターミナルは、JupyterのTerminalを起動するか、sshでJetBotにログインするか、キーボード+マウス+モニターをJetBotに接続してCtrl+ALT+Tでターミナルを開くことができます。\n",
    "\n",
    "* MAX-N mode:ビルド時間を短くするために、Jetsonの最高性能を出すためのモードに変更します。\n",
    "> sudo nvpmodel -m 0\n",
    "\n",
    "* nodejs:マウスクリックウィジェットで必要になります。\n",
    "> sudo python3 -m pip install git+https://github.com/ipython/traitlets@dead2b8cdde  \n",
    "sudo apt-get install -y curl  \n",
    "curl -sL https://deb.nodesource.com/setup_10.x | sudo -E bash -  \n",
    "sudo apt-get install -y nodejs libffi-dev  \n",
    "\n",
    "* jupyter_clickable_image_widget:マウスクリックウィジェット\n",
    "> cd\n",
    "git clone https://github.com/jaybdub/jupyter_clickable_image_widget  \n",
    "cd jupyter_clickable_image_widget  \n",
    "sudo -H pip3 install -e .  \n",
    "sudo jupyter labextension install js  \n",
    "\n",
    "* bokeh:グラフ表示ウィジェット\n",
    "> sudo apt-get install -y python3-matplotlib  \n",
    "sudo -H pip3 install bokeh  \n",
    "sudo jupyter labextension install @bokeh/jupyter_bokeh  \n",
    "\n",
    "* 5W mode:5V3Aのモバイルバッテリーでは15Wモードの安定動作は電流的に厳しいので、5Wモードに変更します。\n",
    "> sudo nvpmodel -m 1\n",
    "\n",
    "* reboot:再起動します。モバイルバッテリーで15Wモードのまま再起動すると起動しないことがあります。その場合は5VのACアダプターを使って起動後、5Wモードに変更してください。\n",
    "> sudo reboot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "road followingではtorchvisionで用意されているResNet18モデルを少し変更して使います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import glob\n",
    "import PIL.Image\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Dataset Instance(データセットインスタンスの作成)\n",
    "\n",
    "[torch.utils.data.DataLoader](https://github.com/pytorch/pytorch/blob/master/torch/utils/data/dataloader.py)クラスを継承して``__len__`` と ``__getitem__``関数を実装実装した``XYDataset``クラスを作成します。このクラスは、画像をロードするための役割と、画像ファイル名からx,y値の値をパースして取得します。[torch.utils.data.DataLoader](https://github.com/pytorch/pytorch/blob/master/torch/utils/data/dataloader.py)を継承する事で、すべてのtorchデータユーティリティを使用する事ができます。\n",
    "\n",
    "いくつかの変換（カラージッターなど）をデータセットにハードコーディングしました。カラージッターは画像の明るさ、コントラスト、彩度をランダムに変更します。  \n",
    "ランダムに水平反転を有効にするオプション``random_hflips``を付けました。デフォルトは有効にしています。水平反転は「右車線にとどまる」必要が無い場合、つまり左右どちらの車線を通ってもいい場合に有効にすることでデータセットの特性が変わります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_x(path):\n",
    "    \"\"\"Gets the x value from the image filename\"\"\"\n",
    "    return (float(int(path[3:6])) - 50.0) / 50.0\n",
    "\n",
    "def get_y(path):\n",
    "    \"\"\"Gets the y value from the image filename\"\"\"\n",
    "    return (float(int(path[7:10])) - 50.0) / 50.0\n",
    "\n",
    "class XYDataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, directory, random_hflips=False):\n",
    "        self.image_paths = glob.glob(os.path.join(directory, '*.jpg'))\n",
    "        self.random_hflips = random_hflips\n",
    "        self.color_jitter = transforms.ColorJitter(0.3, 0.3, 0.3, 0.3)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        \n",
    "        image = PIL.Image.open(image_path)\n",
    "        x = float(get_x(os.path.basename(image_path)))\n",
    "        y = float(get_y(os.path.basename(image_path)))\n",
    "        # ランダムに画像を水平反転する時、出力のxも対応するように反転する\n",
    "        if self.random_hflips:\n",
    "            if float(np.random.rand(1)) > 0.5:\n",
    "                image = transforms.functional.hflip(image)\n",
    "                x = -x\n",
    "\n",
    "        # 画像をモデル学習の入力用データフォーマットに変換する\n",
    "        image = self.color_jitter(image)\n",
    "        image = transforms.functional.resize(image, (224, 224))\n",
    "        image = transforms.functional.to_tensor(image)\n",
    "        image = image.numpy()[::-1].copy()\n",
    "        image = torch.from_numpy(image)\n",
    "        # ImageNetの正規化と同じパラメータでデータを正規化する\n",
    "        image = transforms.functional.normalize(image, [0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "\n",
    "        return image, torch.tensor([x, y]).float()\n",
    "    \n",
    "dataset = XYDataset('../dataset_xy', random_hflips=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split dataset into train and test sets(トレーニングデータとテストデータに分ける)\n",
    "次に、データセットを*トレーニング用*と*テスト用*のデータセットに分割します。この例では、*トレーニング用*に90%, *テスト用*に10%で分けます。*テスト用*のデータセットは、学習中にモデルの精度を検証するために使用されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_percent = 0.1\n",
    "num_test = int(test_percent * len(dataset))\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [len(dataset) - num_test, num_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create data loaders to load data in batches(バッチ処理で学習データとテストデータを読み込むためのデータローダーを作成)\n",
    "\n",
    "[torch.utils.data.DataLoader](https://github.com/pytorch/pytorch/blob/master/torch/utils/data/dataloader.py)クラスは、モデル学習中に次のデータ処理が完了出来るようにサブプロセスで並列処理にして実装します。  \n",
    "データのシャッフル、バッチでのデータロードのために使用します。この例では、1回のバッチ処理で8枚の画像を使用します。これをバッチサイズと呼び、GPUのメモリ使用量と、モデルの精度に影響を与えます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=8,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=8,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Neural Network Model (JetBot用にモデルを変更する)\n",
    "\n",
    "torchvisionで使用可能なImageNetデータセットで学習済みのResNet18モデルを使用します。\n",
    "\n",
    "*転移学習*と呼ばれる手法で、すでに画像分類できる特徴を持つニューラルネットワーク層を、別の目的のために作られたモデルに適用することで、短時間で良好な結果を得られるモデルを作成することができます。\n",
    "\n",
    "ResNet18の詳細: https://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py\n",
    "\n",
    "転移学習の詳細：https://www.youtube.com/watch?v=yofjFQddwHE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ResNet18モデルはImageNetを学習するために作られているため、1000種類の画像分類が可能な出力を持っています。ResNet18モデル構造の全結合層(fully connected layer)を入れ替えて、JetBotで欲しい出力x,yの2種類を得られるモデル構造にします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n"
     ]
    }
   ],
   "source": [
    "print(model.fc.in_features)\n",
    "model.fc = torch.nn.Linear(model.fc.in_features, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "デフォルトではモデルのweightはCPUで処理されるため、GPUを利用するようにモデルを設定します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before: torch.FloatTensor\n",
      "after: torch.cuda.FloatTensor\n"
     ]
    }
   ],
   "source": [
    "print(\"before: {}\".format(model.fc.weight.type()))\n",
    "device = torch.device('cuda')\n",
    "model = model.to(device)\n",
    "print(\"after: {}\".format(model.fc.weight.type()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning(ファインチューニング)\n",
    "初めての学習では、この項目はスキップして**「視覚化ユーティリティ」**に進んでください。  \n",
    "学習データが500件を超えて、学習時間が遅くなってきた時にファインチューニングが役立ちます。\n",
    "\n",
    "学習データが800枚にもなると、学習に必要なメモリ容量が増えてきてSWAPが多く消費されるため、学習速度が大幅に低下してしまいます。  \n",
    "この時、再学習するネットワーク層を限定することで学習時のメモリ使用量を減らしながら、高速に学習を進めることが可能となります。  \n",
    "全結合層(`fully-connected layer`)だけを再学習しても、なかなか成果につながりにくいため、ここでは[ResNet18](https://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py)モデルの`fc`と`layer4`を再学習させることにします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルを凍結して使う場合は、全てのパラメータが持つ学習フラグを無効化します。デフォルトはrequires_grad = Trueで全てのパラメータを再学習します。\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight\n",
      "bn1.weight\n",
      "bn1.bias\n",
      "layer1.0.conv1.weight\n",
      "layer1.0.bn1.weight\n",
      "layer1.0.bn1.bias\n",
      "layer1.0.conv2.weight\n",
      "layer1.0.bn2.weight\n",
      "layer1.0.bn2.bias\n",
      "layer1.1.conv1.weight\n",
      "layer1.1.bn1.weight\n",
      "layer1.1.bn1.bias\n",
      "layer1.1.conv2.weight\n",
      "layer1.1.bn2.weight\n",
      "layer1.1.bn2.bias\n",
      "layer2.0.conv1.weight\n",
      "layer2.0.bn1.weight\n",
      "layer2.0.bn1.bias\n",
      "layer2.0.conv2.weight\n",
      "layer2.0.bn2.weight\n",
      "layer2.0.bn2.bias\n",
      "layer2.0.downsample.0.weight\n",
      "layer2.0.downsample.1.weight\n",
      "layer2.0.downsample.1.bias\n",
      "layer2.1.conv1.weight\n",
      "layer2.1.bn1.weight\n",
      "layer2.1.bn1.bias\n",
      "layer2.1.conv2.weight\n",
      "layer2.1.bn2.weight\n",
      "layer2.1.bn2.bias\n",
      "layer3.0.conv1.weight\n",
      "layer3.0.bn1.weight\n",
      "layer3.0.bn1.bias\n",
      "layer3.0.conv2.weight\n",
      "layer3.0.bn2.weight\n",
      "layer3.0.bn2.bias\n",
      "layer3.0.downsample.0.weight\n",
      "layer3.0.downsample.1.weight\n",
      "layer3.0.downsample.1.bias\n",
      "layer3.1.conv1.weight\n",
      "layer3.1.bn1.weight\n",
      "layer3.1.bn1.bias\n",
      "layer3.1.conv2.weight\n",
      "layer3.1.bn2.weight\n",
      "layer3.1.bn2.bias\n",
      "layer4.0.conv1.weight\n",
      "layer4.0.bn1.weight\n",
      "layer4.0.bn1.bias\n",
      "layer4.0.conv2.weight\n",
      "layer4.0.bn2.weight\n",
      "layer4.0.bn2.bias\n",
      "layer4.0.downsample.0.weight\n",
      "layer4.0.downsample.1.weight\n",
      "layer4.0.downsample.1.bias\n",
      "layer4.1.conv1.weight\n",
      "layer4.1.bn1.weight\n",
      "layer4.1.bn1.bias\n",
      "layer4.1.conv2.weight\n",
      "layer4.1.bn2.weight\n",
      "layer4.1.bn2.bias\n",
      "fc.weight\n",
      "fc.bias\n"
     ]
    }
   ],
   "source": [
    "# 特定のネットワーク層の凍結を解除して再学習させるために、パラメータ名を確認します。\n",
    "for name, param in model.named_parameters():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "全結合層(`fc`)と`layer4`を再学習させます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fcとlayer4を再学習させます。fcは入れ替えているので必ず学習させてください。\n",
    "for name, param in model.named_parameters():\n",
    "    if name.startswith(\"layer4\"):\n",
    "        param.requires_grad = True\n",
    "    if name.startswith(\"fc\"):\n",
    "        param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer4.0.conv1.weight\n",
      "layer4.0.bn1.weight\n",
      "layer4.0.bn1.bias\n",
      "layer4.0.conv2.weight\n",
      "layer4.0.bn2.weight\n",
      "layer4.0.bn2.bias\n",
      "layer4.0.downsample.0.weight\n",
      "layer4.0.downsample.1.weight\n",
      "layer4.0.downsample.1.bias\n",
      "layer4.1.conv1.weight\n",
      "layer4.1.bn1.weight\n",
      "layer4.1.bn1.bias\n",
      "layer4.1.conv2.weight\n",
      "layer4.1.bn2.weight\n",
      "layer4.1.bn2.bias\n",
      "fc.weight\n",
      "fc.bias\n"
     ]
    }
   ],
   "source": [
    "# 再学習させるパラメータを確認します。\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このように、特定の層を選んで再学習させることもできます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 視覚化ユーティリティ\n",
    "[bokeh](https://docs.bokeh.org/en/latest/docs/installation.html)を使って学習中の損失(loss)と精度(accuracy)をグラフに表示することができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"1414\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"1414\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error() {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < css_urls.length; i++) {\n",
       "      var url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    const hashes = {\"https://cdn.bokeh.org/bokeh/release/bokeh-2.2.1.min.js\": \"qkRvDQVAIfzsJo40iRBbxt6sttt0hv4lh74DG7OK4MCHv4C5oohXYoHUM5W11uqS\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.2.1.min.js\": \"Sb7Mr06a9TNlet/GEBeKaf5xH3eb6AlCzwjtU82wNPyDrnfoiVl26qnvlKjmcAd+\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.2.1.min.js\": \"HaJ15vgfmcfRtB4c4YBOI4f1MUujukqInOWVqZJZZGK7Q+ivud0OKGSTn/Vm2iso\"};\n",
       "\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      if (url in hashes) {\n",
       "        element.crossOrigin = \"anonymous\";\n",
       "        element.integrity = \"sha384-\" + hashes[url];\n",
       "      }\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  \n",
       "  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.2.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.2.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.2.1.min.js\"];\n",
       "  var css_urls = [];\n",
       "  \n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "    \n",
       "    \n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if (root.Bokeh !== undefined || force === true) {\n",
       "      \n",
       "    for (var i = 0; i < inline_js.length; i++) {\n",
       "      inline_js[i].call(root, root.Bokeh);\n",
       "    }\n",
       "    if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"1414\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"1414\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    const hashes = {\"https://cdn.bokeh.org/bokeh/release/bokeh-2.2.1.min.js\": \"qkRvDQVAIfzsJo40iRBbxt6sttt0hv4lh74DG7OK4MCHv4C5oohXYoHUM5W11uqS\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.2.1.min.js\": \"Sb7Mr06a9TNlet/GEBeKaf5xH3eb6AlCzwjtU82wNPyDrnfoiVl26qnvlKjmcAd+\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.2.1.min.js\": \"HaJ15vgfmcfRtB4c4YBOI4f1MUujukqInOWVqZJZZGK7Q+ivud0OKGSTn/Vm2iso\"};\n\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      if (url in hashes) {\n        element.crossOrigin = \"anonymous\";\n        element.integrity = \"sha384-\" + hashes[url];\n      }\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  \n  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.2.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.2.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.2.1.min.js\"];\n  var css_urls = [];\n  \n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    function(Bokeh) {\n    \n    \n    }\n  ];\n\n  function run_inline_js() {\n    \n    if (root.Bokeh !== undefined || force === true) {\n      \n    for (var i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n    if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"1414\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from bokeh.io import push_notebook, show, output_notebook\n",
    "from bokeh.layouts import row\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.models import ColumnDataSource\n",
    "from bokeh.models.tickers import SingleIntervalTicker\n",
    "output_notebook()\n",
    "\n",
    "colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728']\n",
    "\n",
    "p1 = figure(title=\"Loss\", x_axis_label=\"Epoch\", plot_height=300, plot_width=360)\n",
    "p2 = figure(title=\"Accuracy\", x_axis_label=\"Epoch\", plot_height=300, plot_width=360)\n",
    "\n",
    "source1 = ColumnDataSource(data={'epochs': [], 'trainlosses': [], 'testlosses': [] })\n",
    "source2 = ColumnDataSource(data={'epochs': [], 'train_accuracies': [], 'test_accuracies': []})\n",
    "\n",
    "#r = p1.multi_line(ys=['trainlosses', 'testlosses'], xs='epochs', color=colors, alpha=0.8, legend_label=['Training','Test'], source=source)\n",
    "r1 = p1.line(x='epochs', y='trainlosses', line_width=2, color=colors[0], alpha=0.8, legend_label=\"Train\", source=source1)\n",
    "r2 = p1.line(x='epochs', y='testlosses', line_width=2, color=colors[1], alpha=0.8, legend_label=\"Test\", source=source1)\n",
    "\n",
    "r3 = p2.line(x='epochs', y='train_accuracies', line_width=2, color=colors[0], alpha=0.8, legend_label=\"Train\", source=source2)\n",
    "r4 = p2.line(x='epochs', y='test_accuracies', line_width=2, color=colors[1], alpha=0.8, legend_label=\"Test\", source=source2)\n",
    "\n",
    "p1.legend.location = \"top_right\"\n",
    "p1.legend.click_policy=\"hide\"\n",
    "\n",
    "p2.legend.location = \"bottom_right\"\n",
    "p2.legend.click_policy=\"hide\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training(モデルの学習)\n",
    "\n",
    "20エポック学習し、各エポックで以前の最高精度と現在の精度を比較することにより、最高精度を更新した場合に保存します。  \n",
    "現在の精度が以前の最高精度と等しい場合は、損失の少ない方を保存します。\n",
    "\n",
    "> 1エポックは、私たちが用意したトレーニング用のデータ全部を1回学習することです。一度に8枚の画像を学習するミニバッチ処理を複数回実行することで1エポックが完了します。\n",
    "\n",
    "**Collision Avoidance**の時は、「free(直進する)」or「blocked(旋回する)」それぞれに対する正解ラベルは`True`or`False`の 0 or 1 で定義できました。また、「free(直進する)」or「blocked(旋回する)」のうち、1つだけが`True`となるため**one hot value**として定義できました。**one hot value**を予測する場合、モデルの精度の定義はテストデータでの予測結果が、**「正解ラベルと一致している件数」÷「テストデータの総数」**となります。\n",
    "\n",
    "**Road Following**では正解ラベルはx,yの2出力それぞれ[-1.0,1.0]のfloat型の範囲になります。このため、正解ラベルと一致しない場合が多くなり、精度の定義は難しくなります。この場合、最低損失を更新した場合にモデルを保存します。\n",
    "\n",
    "今回は、Collision Avoidanceと同じような学習コードの構成にしたいので、何らかの方法で精度を定義したいとおもいます。  \n",
    "ここでは`MSE`をlossとして定義しているため、`1.0 - RMSE`をaccuracyとして定義することにします。\n",
    "\n",
    "one hot valueの詳細：https://www.youtube.com/watch?v=v_4KWmkwmsU  \n",
    "回帰モデルの評価指標の詳細：https://www.ritchieng.com/machine-learning-evaluate-linear-regression-model/#15.-Model-Evaluation-Metrics-for-Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "  <div class=\"bk-root\" id=\"97ea2da0-843b-4a24-a294-dc7e6195d3de\" data-root-id=\"1541\"></div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function embed_document(root) {\n",
       "    \n",
       "  var docs_json = {\"9a92d1bb-daae-46a0-8107-f0e258436a63\":{\"roots\":{\"references\":[{\"attributes\":{\"children\":[{\"id\":\"1415\"},{\"id\":\"1448\"}]},\"id\":\"1541\",\"type\":\"Row\"},{\"attributes\":{},\"id\":\"1427\",\"type\":\"BasicTicker\"},{\"attributes\":{},\"id\":\"1457\",\"type\":\"LinearScale\"},{\"attributes\":{},\"id\":\"1418\",\"type\":\"DataRange1d\"},{\"attributes\":{\"text\":\"Loss\"},\"id\":\"1416\",\"type\":\"Title\"},{\"attributes\":{\"axis\":{\"id\":\"1426\"},\"ticker\":null},\"id\":\"1429\",\"type\":\"Grid\"},{\"attributes\":{},\"id\":\"1522\",\"type\":\"Selection\"},{\"attributes\":{\"label\":{\"value\":\"Train\"},\"renderers\":[{\"id\":\"1486\"}]},\"id\":\"1497\",\"type\":\"LegendItem\"},{\"attributes\":{\"axis\":{\"id\":\"1430\"},\"dimension\":1,\"ticker\":null},\"id\":\"1433\",\"type\":\"Grid\"},{\"attributes\":{\"click_policy\":\"hide\",\"items\":[{\"id\":\"1497\"},{\"id\":\"1511\"}]},\"id\":\"1496\",\"type\":\"Legend\"},{\"attributes\":{\"axis_label\":\"Epoch\",\"formatter\":{\"id\":\"1520\"},\"ticker\":{\"id\":\"1460\"}},\"id\":\"1459\",\"type\":\"LinearAxis\"},{\"attributes\":{\"source\":{\"id\":\"1482\"}},\"id\":\"1516\",\"type\":\"CDSView\"},{\"attributes\":{},\"id\":\"1523\",\"type\":\"UnionRenderers\"},{\"attributes\":{\"overlay\":{\"id\":\"1440\"}},\"id\":\"1436\",\"type\":\"BoxZoomTool\"},{\"attributes\":{},\"id\":\"1467\",\"type\":\"PanTool\"},{\"attributes\":{\"formatter\":{\"id\":\"1489\"},\"ticker\":{\"id\":\"1431\"}},\"id\":\"1430\",\"type\":\"LinearAxis\"},{\"attributes\":{\"label\":{\"value\":\"Test\"},\"renderers\":[{\"id\":\"1501\"}]},\"id\":\"1511\",\"type\":\"LegendItem\"},{\"attributes\":{\"data_source\":{\"id\":\"1482\"},\"glyph\":{\"id\":\"1513\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"1514\"},\"selection_glyph\":null,\"view\":{\"id\":\"1516\"}},\"id\":\"1515\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"text\":\"Accuracy\"},\"id\":\"1449\",\"type\":\"Title\"},{\"attributes\":{\"data_source\":{\"id\":\"1482\"},\"glyph\":{\"id\":\"1528\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"1529\"},\"selection_glyph\":null,\"view\":{\"id\":\"1531\"}},\"id\":\"1530\",\"type\":\"GlyphRenderer\"},{\"attributes\":{},\"id\":\"1518\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"line_alpha\":0.1,\"line_color\":\"#ff7f0e\",\"line_width\":2,\"x\":{\"field\":\"epochs\"},\"y\":{\"field\":\"testlosses\"}},\"id\":\"1500\",\"type\":\"Line\"},{\"attributes\":{\"overlay\":{\"id\":\"1473\"}},\"id\":\"1469\",\"type\":\"BoxZoomTool\"},{\"attributes\":{\"active_drag\":\"auto\",\"active_inspect\":\"auto\",\"active_multi\":null,\"active_scroll\":\"auto\",\"active_tap\":\"auto\",\"tools\":[{\"id\":\"1434\"},{\"id\":\"1435\"},{\"id\":\"1436\"},{\"id\":\"1437\"},{\"id\":\"1438\"},{\"id\":\"1439\"}]},\"id\":\"1441\",\"type\":\"Toolbar\"},{\"attributes\":{\"data\":{\"epochs\":[],\"testlosses\":[],\"trainlosses\":[]},\"selected\":{\"id\":\"1493\"},\"selection_policy\":{\"id\":\"1494\"}},\"id\":\"1481\",\"type\":\"ColumnDataSource\"},{\"attributes\":{\"source\":{\"id\":\"1481\"}},\"id\":\"1502\",\"type\":\"CDSView\"},{\"attributes\":{\"data_source\":{\"id\":\"1481\"},\"glyph\":{\"id\":\"1499\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"1500\"},\"selection_glyph\":null,\"view\":{\"id\":\"1502\"}},\"id\":\"1501\",\"type\":\"GlyphRenderer\"},{\"attributes\":{},\"id\":\"1422\",\"type\":\"LinearScale\"},{\"attributes\":{\"click_policy\":\"hide\",\"items\":[{\"id\":\"1526\"},{\"id\":\"1540\"}],\"location\":\"bottom_right\"},\"id\":\"1525\",\"type\":\"Legend\"},{\"attributes\":{},\"id\":\"1438\",\"type\":\"ResetTool\"},{\"attributes\":{},\"id\":\"1470\",\"type\":\"SaveTool\"},{\"attributes\":{},\"id\":\"1455\",\"type\":\"LinearScale\"},{\"attributes\":{},\"id\":\"1471\",\"type\":\"ResetTool\"},{\"attributes\":{},\"id\":\"1431\",\"type\":\"BasicTicker\"},{\"attributes\":{\"line_alpha\":0.8,\"line_color\":\"#ff7f0e\",\"line_width\":2,\"x\":{\"field\":\"epochs\"},\"y\":{\"field\":\"testlosses\"}},\"id\":\"1499\",\"type\":\"Line\"},{\"attributes\":{\"line_alpha\":0.1,\"line_color\":\"#1f77b4\",\"line_width\":2,\"x\":{\"field\":\"epochs\"},\"y\":{\"field\":\"trainlosses\"}},\"id\":\"1485\",\"type\":\"Line\"},{\"attributes\":{\"active_drag\":\"auto\",\"active_inspect\":\"auto\",\"active_multi\":null,\"active_scroll\":\"auto\",\"active_tap\":\"auto\",\"tools\":[{\"id\":\"1467\"},{\"id\":\"1468\"},{\"id\":\"1469\"},{\"id\":\"1470\"},{\"id\":\"1471\"},{\"id\":\"1472\"}]},\"id\":\"1474\",\"type\":\"Toolbar\"},{\"attributes\":{},\"id\":\"1451\",\"type\":\"DataRange1d\"},{\"attributes\":{},\"id\":\"1489\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"line_alpha\":0.8,\"line_color\":\"#ff7f0e\",\"line_width\":2,\"x\":{\"field\":\"epochs\"},\"y\":{\"field\":\"test_accuracies\"}},\"id\":\"1528\",\"type\":\"Line\"},{\"attributes\":{},\"id\":\"1472\",\"type\":\"HelpTool\"},{\"attributes\":{},\"id\":\"1520\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"label\":{\"value\":\"Train\"},\"renderers\":[{\"id\":\"1515\"}]},\"id\":\"1526\",\"type\":\"LegendItem\"},{\"attributes\":{\"data_source\":{\"id\":\"1481\"},\"glyph\":{\"id\":\"1484\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"1485\"},\"selection_glyph\":null,\"view\":{\"id\":\"1487\"}},\"id\":\"1486\",\"type\":\"GlyphRenderer\"},{\"attributes\":{},\"id\":\"1453\",\"type\":\"DataRange1d\"},{\"attributes\":{\"line_alpha\":0.8,\"line_color\":\"#1f77b4\",\"line_width\":2,\"x\":{\"field\":\"epochs\"},\"y\":{\"field\":\"train_accuracies\"}},\"id\":\"1513\",\"type\":\"Line\"},{\"attributes\":{\"line_alpha\":0.1,\"line_color\":\"#ff7f0e\",\"line_width\":2,\"x\":{\"field\":\"epochs\"},\"y\":{\"field\":\"test_accuracies\"}},\"id\":\"1529\",\"type\":\"Line\"},{\"attributes\":{},\"id\":\"1435\",\"type\":\"WheelZoomTool\"},{\"attributes\":{\"line_alpha\":0.1,\"line_color\":\"#1f77b4\",\"line_width\":2,\"x\":{\"field\":\"epochs\"},\"y\":{\"field\":\"train_accuracies\"}},\"id\":\"1514\",\"type\":\"Line\"},{\"attributes\":{\"data\":{\"epochs\":[],\"test_accuracies\":[],\"train_accuracies\":[]},\"selected\":{\"id\":\"1522\"},\"selection_policy\":{\"id\":\"1523\"}},\"id\":\"1482\",\"type\":\"ColumnDataSource\"},{\"attributes\":{\"bottom_units\":\"screen\",\"fill_alpha\":0.5,\"fill_color\":\"lightgrey\",\"left_units\":\"screen\",\"level\":\"overlay\",\"line_alpha\":1.0,\"line_color\":\"black\",\"line_dash\":[4,4],\"line_width\":2,\"right_units\":\"screen\",\"top_units\":\"screen\"},\"id\":\"1440\",\"type\":\"BoxAnnotation\"},{\"attributes\":{\"source\":{\"id\":\"1481\"}},\"id\":\"1487\",\"type\":\"CDSView\"},{\"attributes\":{},\"id\":\"1434\",\"type\":\"PanTool\"},{\"attributes\":{},\"id\":\"1491\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{},\"id\":\"1494\",\"type\":\"UnionRenderers\"},{\"attributes\":{\"below\":[{\"id\":\"1459\"}],\"center\":[{\"id\":\"1462\"},{\"id\":\"1466\"},{\"id\":\"1525\"}],\"left\":[{\"id\":\"1463\"}],\"plot_height\":300,\"plot_width\":360,\"renderers\":[{\"id\":\"1515\"},{\"id\":\"1530\"}],\"title\":{\"id\":\"1449\"},\"toolbar\":{\"id\":\"1474\"},\"x_range\":{\"id\":\"1451\"},\"x_scale\":{\"id\":\"1455\"},\"y_range\":{\"id\":\"1453\"},\"y_scale\":{\"id\":\"1457\"}},\"id\":\"1448\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{\"source\":{\"id\":\"1482\"}},\"id\":\"1531\",\"type\":\"CDSView\"},{\"attributes\":{},\"id\":\"1424\",\"type\":\"LinearScale\"},{\"attributes\":{\"bottom_units\":\"screen\",\"fill_alpha\":0.5,\"fill_color\":\"lightgrey\",\"left_units\":\"screen\",\"level\":\"overlay\",\"line_alpha\":1.0,\"line_color\":\"black\",\"line_dash\":[4,4],\"line_width\":2,\"right_units\":\"screen\",\"top_units\":\"screen\"},\"id\":\"1473\",\"type\":\"BoxAnnotation\"},{\"attributes\":{\"line_alpha\":0.8,\"line_color\":\"#1f77b4\",\"line_width\":2,\"x\":{\"field\":\"epochs\"},\"y\":{\"field\":\"trainlosses\"}},\"id\":\"1484\",\"type\":\"Line\"},{\"attributes\":{},\"id\":\"1439\",\"type\":\"HelpTool\"},{\"attributes\":{\"axis_label\":\"Epoch\",\"formatter\":{\"id\":\"1491\"},\"ticker\":{\"id\":\"1427\"}},\"id\":\"1426\",\"type\":\"LinearAxis\"},{\"attributes\":{},\"id\":\"1493\",\"type\":\"Selection\"},{\"attributes\":{},\"id\":\"1464\",\"type\":\"BasicTicker\"},{\"attributes\":{},\"id\":\"1460\",\"type\":\"BasicTicker\"},{\"attributes\":{\"label\":{\"value\":\"Test\"},\"renderers\":[{\"id\":\"1530\"}]},\"id\":\"1540\",\"type\":\"LegendItem\"},{\"attributes\":{\"formatter\":{\"id\":\"1518\"},\"ticker\":{\"id\":\"1464\"}},\"id\":\"1463\",\"type\":\"LinearAxis\"},{\"attributes\":{\"axis\":{\"id\":\"1459\"},\"ticker\":null},\"id\":\"1462\",\"type\":\"Grid\"},{\"attributes\":{},\"id\":\"1420\",\"type\":\"DataRange1d\"},{\"attributes\":{},\"id\":\"1437\",\"type\":\"SaveTool\"},{\"attributes\":{\"below\":[{\"id\":\"1426\"}],\"center\":[{\"id\":\"1429\"},{\"id\":\"1433\"},{\"id\":\"1496\"}],\"left\":[{\"id\":\"1430\"}],\"plot_height\":300,\"plot_width\":360,\"renderers\":[{\"id\":\"1486\"},{\"id\":\"1501\"}],\"title\":{\"id\":\"1416\"},\"toolbar\":{\"id\":\"1441\"},\"x_range\":{\"id\":\"1418\"},\"x_scale\":{\"id\":\"1422\"},\"y_range\":{\"id\":\"1420\"},\"y_scale\":{\"id\":\"1424\"}},\"id\":\"1415\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{},\"id\":\"1468\",\"type\":\"WheelZoomTool\"},{\"attributes\":{\"axis\":{\"id\":\"1463\"},\"dimension\":1,\"ticker\":null},\"id\":\"1466\",\"type\":\"Grid\"}],\"root_ids\":[\"1541\"]},\"title\":\"Bokeh Application\",\"version\":\"2.2.1\"}};\n",
       "  var render_items = [{\"docid\":\"9a92d1bb-daae-46a0-8107-f0e258436a63\",\"notebook_comms_target\":\"1590\",\"root_ids\":[\"1541\"],\"roots\":{\"1541\":\"97ea2da0-843b-4a24-a294-dc7e6195d3de\"}}];\n",
       "  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "\n",
       "  }\n",
       "  if (root.Bokeh !== undefined) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (root.Bokeh !== undefined) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else {\n",
       "        attempts++;\n",
       "        if (attempts > 100) {\n",
       "          clearInterval(timer);\n",
       "          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n",
       "        }\n",
       "      }\n",
       "    }, 10, root)\n",
       "  }\n",
       "})(window);"
      ],
      "application/vnd.bokehjs_exec.v0+json": ""
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "id": "1541"
      }
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "学習を開始します。\n",
      "1: 0.058806, 0.025666, 0.969925, 0.977114, saved\n",
      "2: 0.038326, 0.034359, 0.974737, 0.973520, not saved\n",
      "3: 0.027503, 0.007667, 0.978843, 0.987491, saved\n",
      "4: 0.010955, 0.015317, 0.986396, 0.982319, not saved\n",
      "5: 0.017445, 0.004038, 0.984115, 0.990922, saved\n",
      "6: 0.009290, 0.007728, 0.987868, 0.987441, not saved\n",
      "7: 0.011568, 0.003639, 0.985947, 0.991382, saved\n",
      "8: 0.014376, 0.013469, 0.984483, 0.983420, not saved\n",
      "9: 0.016648, 0.006516, 0.983708, 0.988468, not saved\n",
      "10: 0.011728, 0.004290, 0.986031, 0.990643, not saved\n",
      "11: 0.004740, 0.008843, 0.991054, 0.986566, not saved\n",
      "12: 0.007504, 0.004750, 0.988839, 0.990155, not saved\n",
      "13: 0.005521, 0.006092, 0.990503, 0.988850, not saved\n",
      "14: 0.004160, 0.001372, 0.991591, 0.994708, saved\n",
      "15: 0.004651, 0.004644, 0.991154, 0.990264, not saved\n",
      "16: 0.004254, 0.002263, 0.991907, 0.993205, not saved\n",
      "17: 0.003182, 0.004849, 0.992634, 0.990053, not saved\n",
      "18: 0.004017, 0.003816, 0.992084, 0.991176, not saved\n",
      "19: 0.004070, 0.013103, 0.991666, 0.983648, not saved\n",
      "20: 0.007439, 0.003601, 0.988678, 0.991428, not saved\n",
      "21: 0.007048, 0.001760, 0.989410, 0.994007, not saved\n",
      "22: 0.004233, 0.004700, 0.991574, 0.990206, not saved\n",
      "23: 0.005727, 0.004553, 0.990095, 0.990361, not saved\n",
      "24: 0.007682, 0.004830, 0.989011, 0.990072, not saved\n",
      "25: 0.006091, 0.007119, 0.989600, 0.987947, not saved\n",
      "26: 0.006648, 0.005583, 0.989323, 0.989326, not saved\n",
      "27: 0.004551, 0.002652, 0.991379, 0.992643, not saved\n",
      "28: 0.003369, 0.017796, 0.992594, 0.980943, not saved\n",
      "29: 0.004645, 0.003098, 0.991061, 0.992049, not saved\n",
      "30: 0.004447, 0.003660, 0.991501, 0.991358, not saved\n",
      "31: 0.004148, 0.001309, 0.991746, 0.994831, saved\n",
      "32: 0.002501, 0.000690, 0.993713, 0.996248, saved\n",
      "33: 0.002188, 0.001422, 0.993829, 0.994613, not saved\n",
      "34: 0.001742, 0.000631, 0.994595, 0.996410, saved\n",
      "35: 0.002481, 0.001258, 0.994103, 0.994933, not saved\n",
      "36: 0.003850, 0.001265, 0.992025, 0.994919, not saved\n",
      "37: 0.003598, 0.003901, 0.992294, 0.991077, not saved\n",
      "38: 0.004013, 0.000897, 0.992367, 0.995722, not saved\n",
      "39: 0.003365, 0.000543, 0.992538, 0.996670, saved\n",
      "40: 0.002196, 0.000785, 0.993897, 0.995997, not saved\n",
      "41: 0.002022, 0.001301, 0.994204, 0.994847, not saved\n",
      "42: 0.001938, 0.003684, 0.994256, 0.991329, not saved\n",
      "43: 0.002998, 0.001905, 0.993095, 0.993765, not saved\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 70\n",
    "BEST_MODEL_PATH = 'best_finetuned_steering_model_xy.pth'\n",
    "best_accuracy = 0.0\n",
    "saved_loss = 1e9\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "handle = show(row(p1, p2), notebook_handle=True)\n",
    "\n",
    "# create RMSELoss function\n",
    "def RMSELoss(yhat,y):\n",
    "    '''\n",
    "    yhat: predicted value\n",
    "    y: observed value\n",
    "    '''\n",
    "    return torch.sqrt(torch.mean((yhat-y)**2))\n",
    "\n",
    "criterion = RMSELoss\n",
    "\n",
    "print(\"学習を開始します。\")\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    \n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_error_count = 0.0 # for graph\n",
    "    for images, labels in iter(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = F.mse_loss(outputs, labels)\n",
    "        train_loss += float(loss)\n",
    "        train_error_count += criterion(outputs, labels) # for graph\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    train_loss /= len(train_loader)\n",
    "    \n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    test_error_count = 0.0 # for graph\n",
    "    for images, labels in iter(test_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        loss = F.mse_loss(outputs, labels)\n",
    "        test_loss += float(loss)\n",
    "        test_error_count += criterion(outputs, labels) # for graph\n",
    "    test_loss /= len(test_loader)\n",
    "    \n",
    "    train_accuracy = 1.0 - float(train_error_count) / float(len(train_dataset)) # for graph\n",
    "    test_accuracy = 1.0 - float(test_error_count) / float(len(test_dataset)) # for graph\n",
    "\n",
    "    # 今回のepoch学習のテスト結果がよければ保存します\n",
    "    is_saved = False\n",
    "    if test_accuracy > best_accuracy:\n",
    "        torch.save(model.state_dict(), BEST_MODEL_PATH)\n",
    "        best_accuracy = test_accuracy\n",
    "        saved_loss = test_loss\n",
    "        is_saved = True\n",
    "    elif test_accuracy == best_accuracy:\n",
    "        if test_loss < saved_loss:\n",
    "            torch.save(model.state_dict(), BEST_MODEL_PATH)\n",
    "            saved_loss = test_loss\n",
    "            is_saved = True\n",
    "\n",
    "    print('%d: %f, %f, %f, %f, ' % (epoch+1, train_loss, test_loss, train_accuracy, test_accuracy)+(\"saved\" if is_saved else \"not saved\"))\n",
    "\n",
    "    # 学習状況をグラフに表示します\n",
    "    new_data1 = {'epochs': [epoch+1],\n",
    "                 'trainlosses': [float(train_loss)],\n",
    "                 'testlosses': [float(test_loss)] }\n",
    "    source1.stream(new_data1)\n",
    "    new_data2 = {'epochs': [epoch+1],\n",
    "                 'train_accuracies': [float(train_accuracy)],\n",
    "                 'test_accuracies': [float(test_accuracy)] }\n",
    "    source2.stream(new_data2)\n",
    "    push_notebook(handle=handle)\n",
    "print(\"学習を終了しました。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習が完了すると、``live_demo.ipynb``で推論に使う``best_finetuned_steering_model_xy``が生成されます。\n",
    "(生成されるフォルダの場所に注意してください、``live_demo.ipynb``からはmodelの参照先は``./finetuning/best_finetuned_steering_model_xy``にしてください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next(次)\n",
    "\n",
    "次は、``live_demo.ipynb``を実行し、学習済みモデルで自動走行します。  \n",
    "ノートブックメニューから`Kernel`->`Restert Kernel`を選んでJupyter kernelを再起動するか、JetBotを一度再起動してから次に進むとスムーズに進行できます。\n",
    "\n",
    "次は、``train_model.ipynb``で学習をおこないます。  \n",
    "ノートブックメニューから`Kernel`->`Restert Kernel`を選んでJupyter kernelを再起動するか、JetBotを一度再起動してから次に進むとスムーズに進行できます。\n",
    "\n",
    "[live_demo.ipynb](./live_demo.ipynb) をクリックし、移動します。\n",
    "\n",
    "TensorRTを試したい人は、trtフォルダの中の``convert_to_trt.ipynb``を実行し、学習済みモデルをTensorRT形式に変換し、``live_demo_trt.ipynb``を実行し自動走行します。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
